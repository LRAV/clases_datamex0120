{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes, load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_diabetes()\n",
    "diabetes=pd.DataFrame(data.data, columns=data.feature_names)\n",
    "diabetes['target']=data.target\n",
    "\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_wine()\n",
    "wine=pd.DataFrame(data.data, columns=data.feature_names)\n",
    "wine['target']=data.target\n",
    "\n",
    "wine.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d, X_test_d, y_train_d, y_test_d=tts(diabetes.drop('target', axis=1),\n",
    "                                             diabetes.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v, X_test_v, y_train_v, y_test_v=tts(wine.drop('target', axis=1),\n",
    "                                             wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo sgdr\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor as SGDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5027569031159751 0.495012674235993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/data/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "sgdr=SGDR(max_iter=5000)\n",
    "sgdr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=sgdr.score(X_train_d, y_train_d)\n",
    "test_score=sgdr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924812030075187 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# GNB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "\n",
    "gnb=GNB()\n",
    "gnb.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=gnb.score(X_train_v, y_train_v)\n",
    "test_score=gnb.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12c0ab310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "wine.target.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8796992481203008 0.8\n"
     ]
    }
   ],
   "source": [
    "# MNB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "mnb=MNB()\n",
    "mnb.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=mnb.score(X_train_v, y_train_v)\n",
    "test_score=mnb.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6616541353383458 0.6\n"
     ]
    }
   ],
   "source": [
    "# CNB\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB as CNB\n",
    "\n",
    "cnb=CNB()\n",
    "cnb.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=cnb.score(X_train_v, y_train_v)\n",
    "test_score=cnb.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41353383458646614 0.35555555555555557\n"
     ]
    }
   ],
   "source": [
    "# BNB\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB as BNB\n",
    "\n",
    "bnb=BNB()\n",
    "bnb.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=bnb.score(X_train_v, y_train_v)\n",
    "test_score=bnb.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KKN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5818951544486498 0.4149577786104134\n"
     ]
    }
   ],
   "source": [
    "# KNNR\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNNR\n",
    "\n",
    "knnr=KNNR(n_neighbors=5)\n",
    "knnr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=knnr.score(X_train_d, y_train_d)\n",
    "test_score=knnr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7368421052631579 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "# KNNC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "\n",
    "knnc=KNNC(n_neighbors=9)\n",
    "knnc.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=knnc.score(X_train_v, y_train_v)\n",
    "test_score=knnc.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8528509027611995 0.32284031207873587\n"
     ]
    }
   ],
   "source": [
    "# GBR\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "gbr=GBR()\n",
    "gbr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=gbr.score(X_train_d, y_train_d)\n",
    "test_score=gbr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# GBC\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "gbc=GBC()\n",
    "gbc.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=gbc.score(X_train_v, y_train_v)\n",
    "test_score=gbc.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/data/Library/Python/3.7/lib/python/site-packages (0.90)\r\n",
      "Requirement already satisfied: numpy in /Users/data/Library/Python/3.7/lib/python/site-packages (from xgboost) (1.17.2)\r\n",
      "Requirement already satisfied: scipy in /Users/data/Library/Python/3.7/lib/python/site-packages (from xgboost) (1.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:38:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.8344383075943241 0.32931058216216924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/data/Library/Python/3.7/lib/python/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "# XGBR\n",
    "\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "\n",
    "xgbr=XGBR()\n",
    "xgbr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=xgbr.score(X_train_d, y_train_d)\n",
    "test_score=xgbr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# XGBC\n",
    "\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "\n",
    "xgbc=XGBC()\n",
    "xgbc.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=xgbc.score(X_train_v, y_train_v)\n",
    "test_score=xgbc.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817024583199715 0.36405912691297926\n"
     ]
    }
   ],
   "source": [
    "# CTR\n",
    "\n",
    "from catboost import CatBoostRegressor as CTR\n",
    "\n",
    "ctr=CTR(verbose=False)\n",
    "ctr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=ctr.score(X_train_d, y_train_d)\n",
    "test_score=ctr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "# CTC\n",
    "\n",
    "from catboost import CatBoostClassifier as CTC\n",
    "\n",
    "\n",
    "ctc=CTC(verbose=False)\n",
    "ctc.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=ctc.score(X_train_v, y_train_v)\n",
    "test_score=ctc.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/data/Library/Python/3.7/lib/python/site-packages (from lightgbm) (1.17.2)\n",
      "Requirement already satisfied: scipy in /Users/data/Library/Python/3.7/lib/python/site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/data/Library/Python/3.7/lib/python/site-packages (from lightgbm) (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/data/Library/Python/3.7/lib/python/site-packages (from scikit-learn->lightgbm) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236903720105877 0.3532283722767897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# LGBMR\n",
    "\n",
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "\n",
    "lgbmr=LGBMR()\n",
    "lgbmr.fit(X_train_d, y_train_d)\n",
    "\n",
    "train_score=lgbmr.score(X_train_d, y_train_d)\n",
    "test_score=lgbmr.score(X_test_d, y_test_d)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# LGBMC\n",
    "\n",
    "from lightgbm import LGBMClassifier as LGBMC\n",
    "\n",
    "\n",
    "lgbmc=LGBMC()\n",
    "lgbmc.fit(X_train_v, y_train_v)\n",
    "\n",
    "train_score=lgbmc.score(X_train_v, y_train_v)\n",
    "test_score=lgbmc.score(X_test_v, y_test_v)\n",
    "\n",
    "print (train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2o\n",
    "\n",
    "https://www.h2o.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_222\"; OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_222-b10); OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.222-b10, mixed mode)\n",
      "  Starting server from /Users/data/Library/Python/3.7/lib/python/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/xx/_vmf5v917hb0dgxz9fw65cnh0000gn/T/tmp0_nyx7hn\n",
      "  JVM stdout: /var/folders/xx/_vmf5v917hb0dgxz9fw65cnh0000gn/T/tmp0_nyx7hn/h2o_data_started_from_python.out\n",
      "  JVM stderr: /var/folders/xx/_vmf5v917hb0dgxz9fw65cnh0000gn/T/tmp0_nyx7hn/h2o_data_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Mexico_City</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.10</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_data_bhs1ol</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Mexico_City\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.10\n",
       "H2O cluster version age:    3 months and 5 days\n",
       "H2O cluster name:           H2O_from_python_data_bhs1ol\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.6 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "url='https://s3.amazonaws.com/erin-data/higgs/'\n",
    "\n",
    "train=h2o.import_file(url+'higgs_train_10k.csv')\n",
    "test=h2o.import_file(url+'higgs_test_5k.csv')\n",
    "\n",
    "\n",
    "X=train.columns\n",
    "y='response'\n",
    "X.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor para clasificacion binaria\n",
    "\n",
    "train[y]=train[y].asfactor()\n",
    "test[y]=test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# 20 modelos de base\n",
    "\n",
    "aml=H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=X, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200213_115237   </td><td style=\"text-align: right;\">0.790376</td><td style=\"text-align: right;\"> 0.550893</td><td style=\"text-align: right;\">              0.319851</td><td style=\"text-align: right;\">0.431873</td><td style=\"text-align: right;\">0.186514</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200213_115237</td><td style=\"text-align: right;\">0.789123</td><td style=\"text-align: right;\"> 0.551545</td><td style=\"text-align: right;\">              0.315609</td><td style=\"text-align: right;\">0.432336</td><td style=\"text-align: right;\">0.186915</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200213_115237_model_4      </td><td style=\"text-align: right;\">0.785011</td><td style=\"text-align: right;\"> 0.556344</td><td style=\"text-align: right;\">              0.318063</td><td style=\"text-align: right;\">0.434527</td><td style=\"text-align: right;\">0.188814</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20200213_115237                   </td><td style=\"text-align: right;\">0.784844</td><td style=\"text-align: right;\"> 0.557121</td><td style=\"text-align: right;\">              0.311898</td><td style=\"text-align: right;\">0.434717</td><td style=\"text-align: right;\">0.188979</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20200213_115237                   </td><td style=\"text-align: right;\">0.784043</td><td style=\"text-align: right;\"> 0.555627</td><td style=\"text-align: right;\">              0.312643</td><td style=\"text-align: right;\">0.434452</td><td style=\"text-align: right;\">0.188748</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200213_115237_model_3      </td><td style=\"text-align: right;\">0.784037</td><td style=\"text-align: right;\"> 0.558918</td><td style=\"text-align: right;\">              0.327596</td><td style=\"text-align: right;\">0.435303</td><td style=\"text-align: right;\">0.189489</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200213_115237_model_1      </td><td style=\"text-align: right;\">0.783577</td><td style=\"text-align: right;\"> 0.559298</td><td style=\"text-align: right;\">              0.336173</td><td style=\"text-align: right;\">0.435577</td><td style=\"text-align: right;\">0.189727</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20200213_115237                   </td><td style=\"text-align: right;\">0.783156</td><td style=\"text-align: right;\"> 0.55631 </td><td style=\"text-align: right;\">              0.322884</td><td style=\"text-align: right;\">0.434894</td><td style=\"text-align: right;\">0.189132</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.780344</td><td style=\"text-align: right;\"> 0.558723</td><td style=\"text-align: right;\">              0.334826</td><td style=\"text-align: right;\">0.436138</td><td style=\"text-align: right;\">0.190216</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.780286</td><td style=\"text-align: right;\"> 0.560701</td><td style=\"text-align: right;\">              0.316822</td><td style=\"text-align: right;\">0.43642 </td><td style=\"text-align: right;\">0.190462</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.77971 </td><td style=\"text-align: right;\"> 0.560845</td><td style=\"text-align: right;\">              0.332059</td><td style=\"text-align: right;\">0.436651</td><td style=\"text-align: right;\">0.190664</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.774661</td><td style=\"text-align: right;\"> 0.56568 </td><td style=\"text-align: right;\">              0.33475 </td><td style=\"text-align: right;\">0.43918 </td><td style=\"text-align: right;\">0.192879</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20200213_115237_model_2      </td><td style=\"text-align: right;\">0.773   </td><td style=\"text-align: right;\"> 0.577489</td><td style=\"text-align: right;\">              0.34726 </td><td style=\"text-align: right;\">0.443367</td><td style=\"text-align: right;\">0.196575</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.769793</td><td style=\"text-align: right;\"> 0.571616</td><td style=\"text-align: right;\">              0.338649</td><td style=\"text-align: right;\">0.441869</td><td style=\"text-align: right;\">0.195248</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200213_115237_model_1          </td><td style=\"text-align: right;\">0.769752</td><td style=\"text-align: right;\"> 0.572583</td><td style=\"text-align: right;\">              0.344331</td><td style=\"text-align: right;\">0.442452</td><td style=\"text-align: right;\">0.195764</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.76334 </td><td style=\"text-align: right;\"> 0.580105</td><td style=\"text-align: right;\">              0.342391</td><td style=\"text-align: right;\">0.445477</td><td style=\"text-align: right;\">0.198449</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200213_115237                       </td><td style=\"text-align: right;\">0.76257 </td><td style=\"text-align: right;\"> 0.582324</td><td style=\"text-align: right;\">              0.347   </td><td style=\"text-align: right;\">0.446207</td><td style=\"text-align: right;\">0.199101</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20200213_115237_model_2          </td><td style=\"text-align: right;\">0.752753</td><td style=\"text-align: right;\"> 0.931836</td><td style=\"text-align: right;\">              0.345093</td><td style=\"text-align: right;\">0.496916</td><td style=\"text-align: right;\">0.246926</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200213_115237_model_2 </td><td style=\"text-align: right;\">0.742549</td><td style=\"text-align: right;\"> 0.603503</td><td style=\"text-align: right;\">              0.377054</td><td style=\"text-align: right;\">0.45512 </td><td style=\"text-align: right;\">0.207134</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20200213_115237_model_1 </td><td style=\"text-align: right;\">0.691162</td><td style=\"text-align: right;\"> 0.663016</td><td style=\"text-align: right;\">              0.401813</td><td style=\"text-align: right;\">0.477935</td><td style=\"text-align: right;\">0.228421</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200213_115237              </td><td style=\"text-align: right;\">0.686703</td><td style=\"text-align: right;\"> 0.635628</td><td style=\"text-align: right;\">              0.40542 </td><td style=\"text-align: right;\">0.471149</td><td style=\"text-align: right;\">0.221981</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20200213_115237_model_1          </td><td style=\"text-align: right;\">0.682648</td><td style=\"text-align: right;\"> 0.63852 </td><td style=\"text-align: right;\">              0.397234</td><td style=\"text-align: right;\">0.472683</td><td style=\"text-align: right;\">0.223429</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb=aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20200213_115237\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.10560347880546887\n",
      "RMSE: 0.3249668887832557\n",
      "LogLoss: 0.3627364221136404\n",
      "Null degrees of freedom: 9999\n",
      "Residual degrees of freedom: 9984\n",
      "Null deviance: 13828.11338742432\n",
      "Residual deviance: 7254.728442272808\n",
      "AIC: 7286.728442272808\n",
      "AUC: 0.9549543360437684\n",
      "pr_auc: 0.9587969886313777\n",
      "Gini: 0.9099086720875369\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45340095725927376: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3957.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>0.159</td>\n",
       "      <td>(748.0/4705.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>441.0</td>\n",
       "      <td>4854.0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>(441.0/5295.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>4398.0</td>\n",
       "      <td>5602.0</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>(1189.0/10000.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1   Error               Rate\n",
       "0      0  3957.0   748.0   0.159     (748.0/4705.0)\n",
       "1      1   441.0  4854.0  0.0833     (441.0/5295.0)\n",
       "2  Total  4398.0  5602.0  0.1189   (1189.0/10000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.453401</td>\n",
       "      <td>0.890887</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.345681</td>\n",
       "      <td>0.930396</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.597563</td>\n",
       "      <td>0.901039</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.465720</td>\n",
       "      <td>0.881400</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.153486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.465720</td>\n",
       "      <td>0.762081</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.496297</td>\n",
       "      <td>0.875877</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.465720</td>\n",
       "      <td>0.879707</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>5290.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.153486</td>\n",
       "      <td>5295.000000</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.946240</td>\n",
       "      <td>0.999056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.153486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.453401     0.890887  221.0\n",
       "1                        max f2   0.345681     0.930396  265.0\n",
       "2                  max f0point5   0.597563     0.901039  162.0\n",
       "3                  max accuracy   0.465720     0.881400  216.0\n",
       "4                 max precision   0.946240     1.000000    0.0\n",
       "5                    max recall   0.153486     1.000000  356.0\n",
       "6               max specificity   0.946240     1.000000    0.0\n",
       "7              max absolute_mcc   0.465720     0.762081  216.0\n",
       "8    max min_per_class_accuracy   0.496297     0.875877  204.0\n",
       "9   max mean_per_class_accuracy   0.465720     0.879707  216.0\n",
       "10                      max tns   0.946240  4705.000000    0.0\n",
       "11                      max fns   0.946240  5290.000000    0.0\n",
       "12                      max fps   0.052885  4705.000000  399.0\n",
       "13                      max tps   0.153486  5295.000000  356.0\n",
       "14                      max tnr   0.946240     1.000000    0.0\n",
       "15                      max fnr   0.946240     0.999056    0.0\n",
       "16                      max fpr   0.052885     1.000000  399.0\n",
       "17                      max tpr   0.153486     1.000000  356.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 52,95 %, avg score: 51,44 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.922468</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.930747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930747</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.914153</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924375</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.907974</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.910979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919910</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.901893</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.905049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.075543</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.897365</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912853</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.094429</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.872477</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.888574</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.885108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898980</td>\n",
       "      <td>0.094429</td>\n",
       "      <td>0.188857</td>\n",
       "      <td>88.857413</td>\n",
       "      <td>88.857413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.845165</td>\n",
       "      <td>1.881020</td>\n",
       "      <td>1.886056</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.859526</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.885829</td>\n",
       "      <td>0.094051</td>\n",
       "      <td>0.282908</td>\n",
       "      <td>88.101983</td>\n",
       "      <td>88.605603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.814203</td>\n",
       "      <td>1.873466</td>\n",
       "      <td>1.882908</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.829701</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.871797</td>\n",
       "      <td>0.093673</td>\n",
       "      <td>0.376582</td>\n",
       "      <td>87.346553</td>\n",
       "      <td>88.290840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.735832</td>\n",
       "      <td>1.779037</td>\n",
       "      <td>1.848285</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.776179</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.839924</td>\n",
       "      <td>0.177904</td>\n",
       "      <td>0.554485</td>\n",
       "      <td>77.903683</td>\n",
       "      <td>84.828455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.640253</td>\n",
       "      <td>1.667611</td>\n",
       "      <td>1.803116</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.690243</td>\n",
       "      <td>0.954750</td>\n",
       "      <td>0.802504</td>\n",
       "      <td>0.166761</td>\n",
       "      <td>0.721246</td>\n",
       "      <td>66.761095</td>\n",
       "      <td>80.311615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.522686</td>\n",
       "      <td>1.323890</td>\n",
       "      <td>1.707271</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.582652</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.758534</td>\n",
       "      <td>0.132389</td>\n",
       "      <td>0.853636</td>\n",
       "      <td>32.389046</td>\n",
       "      <td>70.727101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.404670</td>\n",
       "      <td>0.923513</td>\n",
       "      <td>1.576645</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.464018</td>\n",
       "      <td>0.834833</td>\n",
       "      <td>0.709448</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>0.945987</td>\n",
       "      <td>-7.648725</td>\n",
       "      <td>57.664463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.404155</td>\n",
       "      <td>1.409146</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.349910</td>\n",
       "      <td>0.746143</td>\n",
       "      <td>0.658085</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.986402</td>\n",
       "      <td>-59.584514</td>\n",
       "      <td>40.914609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.214891</td>\n",
       "      <td>0.111426</td>\n",
       "      <td>1.246931</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.254569</td>\n",
       "      <td>0.660250</td>\n",
       "      <td>0.607646</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.997545</td>\n",
       "      <td>-88.857413</td>\n",
       "      <td>24.693107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.144960</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.180201</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.560152</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-97.544854</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.050353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102498</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>0.514386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                      0.01         0.922468  1.888574   \n",
       "1         2                      0.02         0.914153  1.888574   \n",
       "2         3                      0.03         0.907974  1.888574   \n",
       "3         4                      0.04         0.901893  1.888574   \n",
       "4         5                      0.05         0.897365  1.888574   \n",
       "5         6                      0.10         0.872477  1.888574   \n",
       "6         7                      0.15         0.845165  1.881020   \n",
       "7         8                      0.20         0.814203  1.873466   \n",
       "8         9                      0.30         0.735832  1.779037   \n",
       "9        10                      0.40         0.640253  1.667611   \n",
       "10       11                      0.50         0.522686  1.323890   \n",
       "11       12                      0.60         0.404670  0.923513   \n",
       "12       13                      0.70         0.297908  0.404155   \n",
       "13       14                      0.80         0.214891  0.111426   \n",
       "14       15                      0.90         0.144960  0.024551   \n",
       "15       16                      1.00         0.050353  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.888574          1.000  0.930747                  1.000000   \n",
       "1          1.888574          1.000  0.918004                  1.000000   \n",
       "2          1.888574          1.000  0.910979                  1.000000   \n",
       "3          1.888574          1.000  0.905049                  1.000000   \n",
       "4          1.888574          1.000  0.899484                  1.000000   \n",
       "5          1.888574          1.000  0.885108                  1.000000   \n",
       "6          1.886056          0.996  0.859526                  0.998667   \n",
       "7          1.882908          0.992  0.829701                  0.997000   \n",
       "8          1.848285          0.942  0.776179                  0.978667   \n",
       "9          1.803116          0.883  0.690243                  0.954750   \n",
       "10         1.707271          0.701  0.582652                  0.904000   \n",
       "11         1.576645          0.489  0.464018                  0.834833   \n",
       "12         1.409146          0.214  0.349910                  0.746143   \n",
       "13         1.246931          0.059  0.254569                  0.660250   \n",
       "14         1.111111          0.013  0.180201                  0.588333   \n",
       "15         1.000000          0.000  0.102498                  0.529500   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.930747      0.018886                 0.018886   88.857413   \n",
       "1           0.924375      0.018886                 0.037771   88.857413   \n",
       "2           0.919910      0.018886                 0.056657   88.857413   \n",
       "3           0.916195      0.018886                 0.075543   88.857413   \n",
       "4           0.912853      0.018886                 0.094429   88.857413   \n",
       "5           0.898980      0.094429                 0.188857   88.857413   \n",
       "6           0.885829      0.094051                 0.282908   88.101983   \n",
       "7           0.871797      0.093673                 0.376582   87.346553   \n",
       "8           0.839924      0.177904                 0.554485   77.903683   \n",
       "9           0.802504      0.166761                 0.721246   66.761095   \n",
       "10          0.758534      0.132389                 0.853636   32.389046   \n",
       "11          0.709448      0.092351                 0.945987   -7.648725   \n",
       "12          0.658085      0.040415                 0.986402  -59.584514   \n",
       "13          0.607646      0.011143                 0.997545  -88.857413   \n",
       "14          0.560152      0.002455                 1.000000  -97.544854   \n",
       "15          0.514386      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         88.857413  \n",
       "1         88.857413  \n",
       "2         88.857413  \n",
       "3         88.857413  \n",
       "4         88.857413  \n",
       "5         88.857413  \n",
       "6         88.605603  \n",
       "7         88.290840  \n",
       "8         84.828455  \n",
       "9         80.311615  \n",
       "10        70.727101  \n",
       "11        57.664463  \n",
       "12        40.914609  \n",
       "13        24.693107  \n",
       "14        11.111111  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.18651427126836526\n",
      "RMSE: 0.4318729804796374\n",
      "LogLoss: 0.550893034212991\n",
      "Null degrees of freedom: 9999\n",
      "Residual degrees of freedom: 9984\n",
      "Null deviance: 13829.71731382349\n",
      "Residual deviance: 11017.86068425982\n",
      "AIC: 11049.86068425982\n",
      "AUC: 0.7903759787821406\n",
      "pr_auc: 0.8052338860000745\n",
      "Gini: 0.5807519575642812\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.34214079184973145: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>(2450.0/4705.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>630.0</td>\n",
       "      <td>4665.0</td>\n",
       "      <td>0.119</td>\n",
       "      <td>(630.0/5295.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>7115.0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>(3080.0/10000.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1   Error               Rate\n",
       "0      0  2255.0  2450.0  0.5207    (2450.0/4705.0)\n",
       "1      1   630.0  4665.0   0.119     (630.0/5295.0)\n",
       "2  Total  2885.0  7115.0   0.308   (3080.0/10000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.342141</td>\n",
       "      <td>0.751813</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.159826</td>\n",
       "      <td>0.860978</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.626061</td>\n",
       "      <td>0.740698</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.714400</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.569112</td>\n",
       "      <td>0.430396</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.713496</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.544407</td>\n",
       "      <td>0.715309</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>5287.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>5295.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.066242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.342141     0.751813  277.0\n",
       "1                        max f2   0.159826     0.860978  360.0\n",
       "2                  max f0point5   0.626061     0.740698  151.0\n",
       "3                  max accuracy   0.525735     0.714400  196.0\n",
       "4                 max precision   0.943708     1.000000    0.0\n",
       "5                    max recall   0.066242     1.000000  397.0\n",
       "6               max specificity   0.943708     1.000000    0.0\n",
       "7              max absolute_mcc   0.569112     0.430396  177.0\n",
       "8    max min_per_class_accuracy   0.525735     0.713496  196.0\n",
       "9   max mean_per_class_accuracy   0.544407     0.715309  188.0\n",
       "10                      max tns   0.943708  4705.000000    0.0\n",
       "11                      max fns   0.943708  5287.000000    0.0\n",
       "12                      max fps   0.057312  4705.000000  399.0\n",
       "13                      max tps   0.066242  5295.000000  397.0\n",
       "14                      max tnr   0.943708     1.000000    0.0\n",
       "15                      max fnr   0.943708     0.998489    0.0\n",
       "16                      max fpr   0.057312     1.000000  399.0\n",
       "17                      max tpr   0.066242     1.000000  397.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 52,95 %, avg score: 52,94 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.920895</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.928907</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.928907</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>81.303116</td>\n",
       "      <td>81.303116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.912246</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.915961</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.922434</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>81.303116</td>\n",
       "      <td>81.303116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.905039</td>\n",
       "      <td>1.737488</td>\n",
       "      <td>1.787850</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.909076</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.917981</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.053636</td>\n",
       "      <td>73.748820</td>\n",
       "      <td>78.785017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>1.794145</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.901385</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.913832</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>81.303116</td>\n",
       "      <td>79.414542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.893041</td>\n",
       "      <td>1.699717</td>\n",
       "      <td>1.775260</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.895767</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.910219</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.088763</td>\n",
       "      <td>69.971671</td>\n",
       "      <td>77.525968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.865479</td>\n",
       "      <td>1.726157</td>\n",
       "      <td>1.750708</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.878941</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>0.175071</td>\n",
       "      <td>72.615675</td>\n",
       "      <td>75.070822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.833918</td>\n",
       "      <td>1.612842</td>\n",
       "      <td>1.704753</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.849429</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>0.879530</td>\n",
       "      <td>0.080642</td>\n",
       "      <td>0.255713</td>\n",
       "      <td>61.284230</td>\n",
       "      <td>70.475291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>1.548631</td>\n",
       "      <td>1.665722</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.817632</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.864055</td>\n",
       "      <td>0.077432</td>\n",
       "      <td>0.333144</td>\n",
       "      <td>54.863078</td>\n",
       "      <td>66.572238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.723430</td>\n",
       "      <td>1.403211</td>\n",
       "      <td>1.578218</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.762805</td>\n",
       "      <td>0.835667</td>\n",
       "      <td>0.830305</td>\n",
       "      <td>0.140321</td>\n",
       "      <td>0.473466</td>\n",
       "      <td>40.321058</td>\n",
       "      <td>57.821845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.632170</td>\n",
       "      <td>1.210576</td>\n",
       "      <td>1.486308</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.677367</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.792071</td>\n",
       "      <td>0.121058</td>\n",
       "      <td>0.594523</td>\n",
       "      <td>21.057602</td>\n",
       "      <td>48.630784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.539169</td>\n",
       "      <td>1.070822</td>\n",
       "      <td>1.403211</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.586177</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.750892</td>\n",
       "      <td>0.107082</td>\n",
       "      <td>0.701605</td>\n",
       "      <td>7.082153</td>\n",
       "      <td>40.321058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.443230</td>\n",
       "      <td>0.885741</td>\n",
       "      <td>1.316966</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.490043</td>\n",
       "      <td>0.697333</td>\n",
       "      <td>0.707417</td>\n",
       "      <td>0.088574</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>-11.425873</td>\n",
       "      <td>31.696569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.351360</td>\n",
       "      <td>0.819641</td>\n",
       "      <td>1.245919</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.396974</td>\n",
       "      <td>0.659714</td>\n",
       "      <td>0.663068</td>\n",
       "      <td>0.081964</td>\n",
       "      <td>0.872144</td>\n",
       "      <td>-18.035883</td>\n",
       "      <td>24.591933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.264644</td>\n",
       "      <td>0.619452</td>\n",
       "      <td>1.167611</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.307643</td>\n",
       "      <td>0.618250</td>\n",
       "      <td>0.618640</td>\n",
       "      <td>0.061945</td>\n",
       "      <td>0.934089</td>\n",
       "      <td>-38.054769</td>\n",
       "      <td>16.761095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.175932</td>\n",
       "      <td>0.468366</td>\n",
       "      <td>1.089917</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.223141</td>\n",
       "      <td>0.577111</td>\n",
       "      <td>0.574696</td>\n",
       "      <td>0.046837</td>\n",
       "      <td>0.980925</td>\n",
       "      <td>-53.163362</td>\n",
       "      <td>8.991711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.054123</td>\n",
       "      <td>0.190746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.121376</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>0.529364</td>\n",
       "      <td>0.019075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-80.925401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                      0.01         0.920895  1.813031   \n",
       "1         2                      0.02         0.912246  1.813031   \n",
       "2         3                      0.03         0.905039  1.737488   \n",
       "3         4                      0.04         0.898174  1.813031   \n",
       "4         5                      0.05         0.893041  1.699717   \n",
       "5         6                      0.10         0.865479  1.726157   \n",
       "6         7                      0.15         0.833918  1.612842   \n",
       "7         8                      0.20         0.799600  1.548631   \n",
       "8         9                      0.30         0.723430  1.403211   \n",
       "9        10                      0.40         0.632170  1.210576   \n",
       "10       11                      0.50         0.539169  1.070822   \n",
       "11       12                      0.60         0.443230  0.885741   \n",
       "12       13                      0.70         0.351360  0.819641   \n",
       "13       14                      0.80         0.264644  0.619452   \n",
       "14       15                      0.90         0.175932  0.468366   \n",
       "15       16                      1.00         0.054123  0.190746   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.813031          0.960  0.928907                  0.960000   \n",
       "1          1.813031          0.960  0.915961                  0.960000   \n",
       "2          1.787850          0.920  0.909076                  0.946667   \n",
       "3          1.794145          0.960  0.901385                  0.950000   \n",
       "4          1.775260          0.900  0.895767                  0.940000   \n",
       "5          1.750708          0.914  0.878941                  0.927000   \n",
       "6          1.704753          0.854  0.849429                  0.902667   \n",
       "7          1.665722          0.820  0.817632                  0.882000   \n",
       "8          1.578218          0.743  0.762805                  0.835667   \n",
       "9          1.486308          0.641  0.677367                  0.787000   \n",
       "10         1.403211          0.567  0.586177                  0.743000   \n",
       "11         1.316966          0.469  0.490043                  0.697333   \n",
       "12         1.245919          0.434  0.396974                  0.659714   \n",
       "13         1.167611          0.328  0.307643                  0.618250   \n",
       "14         1.089917          0.248  0.223141                  0.577111   \n",
       "15         1.000000          0.101  0.121376                  0.529500   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.928907      0.018130                 0.018130  81.303116   \n",
       "1           0.922434      0.018130                 0.036261  81.303116   \n",
       "2           0.917981      0.017375                 0.053636  73.748820   \n",
       "3           0.913832      0.018130                 0.071766  81.303116   \n",
       "4           0.910219      0.016997                 0.088763  69.971671   \n",
       "5           0.894580      0.086308                 0.175071  72.615675   \n",
       "6           0.879530      0.080642                 0.255713  61.284230   \n",
       "7           0.864055      0.077432                 0.333144  54.863078   \n",
       "8           0.830305      0.140321                 0.473466  40.321058   \n",
       "9           0.792071      0.121058                 0.594523  21.057602   \n",
       "10          0.750892      0.107082                 0.701605   7.082153   \n",
       "11          0.707417      0.088574                 0.790179 -11.425873   \n",
       "12          0.663068      0.081964                 0.872144 -18.035883   \n",
       "13          0.618640      0.061945                 0.934089 -38.054769   \n",
       "14          0.574696      0.046837                 0.980925 -53.163362   \n",
       "15          0.529364      0.019075                 1.000000 -80.925401   \n",
       "\n",
       "    cumulative_gain  \n",
       "0         81.303116  \n",
       "1         81.303116  \n",
       "2         78.785017  \n",
       "3         79.414542  \n",
       "4         77.525968  \n",
       "5         75.070822  \n",
       "6         70.475291  \n",
       "7         66.572238  \n",
       "8         57.821845  \n",
       "9         48.630784  \n",
       "10        40.321058  \n",
       "11        31.696569  \n",
       "12        24.591933  \n",
       "13        16.761095  \n",
       "14         8.991711  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guarda el mejor modelo\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.77748 </td><td style=\"text-align: right;\">0.22252 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.752631</td><td style=\"text-align: right;\">0.247369</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.624621</td><td style=\"text-align: right;\">0.375379</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.333287</td><td style=\"text-align: right;\">0.666713</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.713781</td><td style=\"text-align: right;\">0.286219</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.270076</td><td style=\"text-align: right;\">0.729924</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.286237</td><td style=\"text-align: right;\">0.713763</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.71425 </td><td style=\"text-align: right;\">0.28575 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.637331</td><td style=\"text-align: right;\">0.362669</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.802783</td><td style=\"text-align: right;\">0.197217</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=aml.leader.predict(test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  response</th><th style=\"text-align: right;\">      x1</th><th style=\"text-align: right;\">       x2</th><th style=\"text-align: right;\">         x3</th><th style=\"text-align: right;\">      x4</th><th style=\"text-align: right;\">       x5</th><th style=\"text-align: right;\">      x6</th><th style=\"text-align: right;\">        x7</th><th style=\"text-align: right;\">        x8</th><th style=\"text-align: right;\">     x9</th><th style=\"text-align: right;\">     x10</th><th style=\"text-align: right;\">      x11</th><th style=\"text-align: right;\">      x12</th><th style=\"text-align: right;\">    x13</th><th style=\"text-align: right;\">     x14</th><th style=\"text-align: right;\">       x15</th><th style=\"text-align: right;\">      x16</th><th style=\"text-align: right;\">    x17</th><th style=\"text-align: right;\">     x18</th><th style=\"text-align: right;\">       x19</th><th style=\"text-align: right;\">        x20</th><th style=\"text-align: right;\">    x21</th><th style=\"text-align: right;\">     x22</th><th style=\"text-align: right;\">     x23</th><th style=\"text-align: right;\">     x24</th><th style=\"text-align: right;\">     x25</th><th style=\"text-align: right;\">     x26</th><th style=\"text-align: right;\">     x27</th><th style=\"text-align: right;\">     x28</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.869293</td><td style=\"text-align: right;\">-0.635082</td><td style=\"text-align: right;\"> 0.22569   </td><td style=\"text-align: right;\">0.32747 </td><td style=\"text-align: right;\">-0.689993</td><td style=\"text-align: right;\">0.754202</td><td style=\"text-align: right;\">-0.248573 </td><td style=\"text-align: right;\">-1.09206  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.37499 </td><td style=\"text-align: right;\">-0.653674</td><td style=\"text-align: right;\"> 0.930349</td><td style=\"text-align: right;\">1.10744</td><td style=\"text-align: right;\">1.1389  </td><td style=\"text-align: right;\">-1.5782   </td><td style=\"text-align: right;\">-1.04699 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.65793 </td><td style=\"text-align: right;\">-0.0104546</td><td style=\"text-align: right;\">-0.0457672 </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">1.35376 </td><td style=\"text-align: right;\">0.979563</td><td style=\"text-align: right;\">0.978076</td><td style=\"text-align: right;\">0.920005</td><td style=\"text-align: right;\">0.721657</td><td style=\"text-align: right;\">0.988751</td><td style=\"text-align: right;\">0.876678</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.907542</td><td style=\"text-align: right;\"> 0.329147</td><td style=\"text-align: right;\"> 0.359412  </td><td style=\"text-align: right;\">1.49797 </td><td style=\"text-align: right;\">-0.31301 </td><td style=\"text-align: right;\">1.09553 </td><td style=\"text-align: right;\">-0.557525 </td><td style=\"text-align: right;\">-1.58823  </td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.812581</td><td style=\"text-align: right;\">-0.213642</td><td style=\"text-align: right;\"> 1.27101 </td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">0.499994</td><td style=\"text-align: right;\">-1.26143  </td><td style=\"text-align: right;\"> 0.732156</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.398701</td><td style=\"text-align: right;\">-1.13893  </td><td style=\"text-align: right;\">-0.00081911</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.30222 </td><td style=\"text-align: right;\">0.833048</td><td style=\"text-align: right;\">0.9857  </td><td style=\"text-align: right;\">0.978098</td><td style=\"text-align: right;\">0.779732</td><td style=\"text-align: right;\">0.992356</td><td style=\"text-align: right;\">0.798343</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.798835</td><td style=\"text-align: right;\"> 1.47064 </td><td style=\"text-align: right;\">-1.63597   </td><td style=\"text-align: right;\">0.453773</td><td style=\"text-align: right;\"> 0.425629</td><td style=\"text-align: right;\">1.10487 </td><td style=\"text-align: right;\"> 1.28232  </td><td style=\"text-align: right;\"> 1.38166  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.851737</td><td style=\"text-align: right;\"> 1.54066 </td><td style=\"text-align: right;\">-0.81969 </td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">0.99349 </td><td style=\"text-align: right;\"> 0.35608  </td><td style=\"text-align: right;\">-0.208778</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.25695 </td><td style=\"text-align: right;\"> 1.12885  </td><td style=\"text-align: right;\"> 0.900461  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.909753</td><td style=\"text-align: right;\">1.10833 </td><td style=\"text-align: right;\">0.985692</td><td style=\"text-align: right;\">0.951331</td><td style=\"text-align: right;\">0.803252</td><td style=\"text-align: right;\">0.865924</td><td style=\"text-align: right;\">0.780118</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">1.34438 </td><td style=\"text-align: right;\">-0.876626</td><td style=\"text-align: right;\"> 0.935913  </td><td style=\"text-align: right;\">1.99205 </td><td style=\"text-align: right;\"> 0.882454</td><td style=\"text-align: right;\">1.78607 </td><td style=\"text-align: right;\">-1.64678  </td><td style=\"text-align: right;\">-0.942383 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">2.42326 </td><td style=\"text-align: right;\">-0.676016</td><td style=\"text-align: right;\"> 0.736159</td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">1.29872 </td><td style=\"text-align: right;\">-1.43074  </td><td style=\"text-align: right;\">-0.364658</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.745313</td><td style=\"text-align: right;\">-0.678379 </td><td style=\"text-align: right;\">-1.36036   </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.946652</td><td style=\"text-align: right;\">1.0287  </td><td style=\"text-align: right;\">0.998656</td><td style=\"text-align: right;\">0.728281</td><td style=\"text-align: right;\">0.8692  </td><td style=\"text-align: right;\">1.02674 </td><td style=\"text-align: right;\">0.957904</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">1.10501 </td><td style=\"text-align: right;\"> 0.321356</td><td style=\"text-align: right;\"> 1.5224    </td><td style=\"text-align: right;\">0.882808</td><td style=\"text-align: right;\">-1.20535 </td><td style=\"text-align: right;\">0.681466</td><td style=\"text-align: right;\">-1.07046  </td><td style=\"text-align: right;\">-0.921871 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.800872</td><td style=\"text-align: right;\"> 1.02097 </td><td style=\"text-align: right;\"> 0.971407</td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">0.596761</td><td style=\"text-align: right;\">-0.350273 </td><td style=\"text-align: right;\"> 0.631194</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.479999</td><td style=\"text-align: right;\">-0.373566 </td><td style=\"text-align: right;\"> 0.113041  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.755856</td><td style=\"text-align: right;\">1.36106 </td><td style=\"text-align: right;\">0.98661 </td><td style=\"text-align: right;\">0.838085</td><td style=\"text-align: right;\">1.1333  </td><td style=\"text-align: right;\">0.872245</td><td style=\"text-align: right;\">0.808487</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">1.59584 </td><td style=\"text-align: right;\">-0.607811</td><td style=\"text-align: right;\"> 0.00707492</td><td style=\"text-align: right;\">1.81845 </td><td style=\"text-align: right;\">-0.111906</td><td style=\"text-align: right;\">0.84755 </td><td style=\"text-align: right;\">-0.566437 </td><td style=\"text-align: right;\"> 1.58124  </td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.755421</td><td style=\"text-align: right;\"> 0.64311 </td><td style=\"text-align: right;\"> 1.42637 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.921661</td><td style=\"text-align: right;\">-1.19043  </td><td style=\"text-align: right;\">-1.61559 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.651114</td><td style=\"text-align: right;\">-0.654227 </td><td style=\"text-align: right;\">-1.27434   </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.823761</td><td style=\"text-align: right;\">0.938191</td><td style=\"text-align: right;\">0.971758</td><td style=\"text-align: right;\">0.789176</td><td style=\"text-align: right;\">0.430553</td><td style=\"text-align: right;\">0.961357</td><td style=\"text-align: right;\">0.957818</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.409391</td><td style=\"text-align: right;\">-1.88468 </td><td style=\"text-align: right;\">-1.02729   </td><td style=\"text-align: right;\">1.67245 </td><td style=\"text-align: right;\">-1.6046  </td><td style=\"text-align: right;\">1.33801 </td><td style=\"text-align: right;\"> 0.0554274</td><td style=\"text-align: right;\"> 0.0134659</td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.509783</td><td style=\"text-align: right;\">-1.03834 </td><td style=\"text-align: right;\"> 0.707862</td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.746918</td><td style=\"text-align: right;\">-0.358465 </td><td style=\"text-align: right;\">-1.64665 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.367058</td><td style=\"text-align: right;\"> 0.0694965</td><td style=\"text-align: right;\"> 1.37713   </td><td style=\"text-align: right;\">3.10196</td><td style=\"text-align: right;\">0.869418</td><td style=\"text-align: right;\">1.22208 </td><td style=\"text-align: right;\">1.00063 </td><td style=\"text-align: right;\">0.545045</td><td style=\"text-align: right;\">0.698653</td><td style=\"text-align: right;\">0.977314</td><td style=\"text-align: right;\">0.828786</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">0.933895</td><td style=\"text-align: right;\"> 0.62913 </td><td style=\"text-align: right;\"> 0.527535  </td><td style=\"text-align: right;\">0.238033</td><td style=\"text-align: right;\">-0.966569</td><td style=\"text-align: right;\">0.547811</td><td style=\"text-align: right;\">-0.0594392</td><td style=\"text-align: right;\">-1.70687  </td><td style=\"text-align: right;\">2.17308</td><td style=\"text-align: right;\">0.941003</td><td style=\"text-align: right;\">-2.65373 </td><td style=\"text-align: right;\">-0.15722 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.03037 </td><td style=\"text-align: right;\">-0.175505 </td><td style=\"text-align: right;\"> 0.523021</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.37355 </td><td style=\"text-align: right;\"> 1.29125  </td><td style=\"text-align: right;\">-1.46745   </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.901837</td><td style=\"text-align: right;\">1.08367 </td><td style=\"text-align: right;\">0.979696</td><td style=\"text-align: right;\">0.7833  </td><td style=\"text-align: right;\">0.849195</td><td style=\"text-align: right;\">0.894356</td><td style=\"text-align: right;\">0.774879</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">1.40514 </td><td style=\"text-align: right;\"> 0.536603</td><td style=\"text-align: right;\"> 0.689554  </td><td style=\"text-align: right;\">1.17957 </td><td style=\"text-align: right;\">-0.110061</td><td style=\"text-align: right;\">3.2024  </td><td style=\"text-align: right;\">-1.52696  </td><td style=\"text-align: right;\">-1.57603  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">2.93154 </td><td style=\"text-align: right;\"> 0.567342</td><td style=\"text-align: right;\">-0.130033</td><td style=\"text-align: right;\">2.21487</td><td style=\"text-align: right;\">1.78712 </td><td style=\"text-align: right;\"> 0.899499 </td><td style=\"text-align: right;\"> 0.585151</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">0.401865</td><td style=\"text-align: right;\">-0.151202 </td><td style=\"text-align: right;\"> 1.16349   </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.66707 </td><td style=\"text-align: right;\">4.03927 </td><td style=\"text-align: right;\">1.17583 </td><td style=\"text-align: right;\">1.04535 </td><td style=\"text-align: right;\">1.54297 </td><td style=\"text-align: right;\">3.53483 </td><td style=\"text-align: right;\">2.74075 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">1.17657 </td><td style=\"text-align: right;\"> 0.104161</td><td style=\"text-align: right;\"> 1.397     </td><td style=\"text-align: right;\">0.479721</td><td style=\"text-align: right;\"> 0.265513</td><td style=\"text-align: right;\">1.13556 </td><td style=\"text-align: right;\"> 1.53483  </td><td style=\"text-align: right;\">-0.253291 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">1.02725 </td><td style=\"text-align: right;\"> 0.534316</td><td style=\"text-align: right;\"> 1.18002 </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">2.40566 </td><td style=\"text-align: right;\"> 0.0875568</td><td style=\"text-align: right;\">-0.976534</td><td style=\"text-align: right;\">2.54822</td><td style=\"text-align: right;\">1.25038 </td><td style=\"text-align: right;\"> 0.268541 </td><td style=\"text-align: right;\"> 0.530334  </td><td style=\"text-align: right;\">0      </td><td style=\"text-align: right;\">0.833175</td><td style=\"text-align: right;\">0.773968</td><td style=\"text-align: right;\">0.98575 </td><td style=\"text-align: right;\">1.1037  </td><td style=\"text-align: right;\">0.84914 </td><td style=\"text-align: right;\">0.937104</td><td style=\"text-align: right;\">0.812364</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/diamonds.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['Unnamed: 0', 'price', 'cut', 'color', 'clarity'])\n",
    "y=df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=tts(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/data/Library/Python/3.7/lib/python/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "n_df['xgbr']=xgbr.fit(X_train, y_train).predict(X_test)\n",
    "n_df['lgbmr']=lgbmr.fit(X_train, y_train).predict(X_test)\n",
    "n_df['ctr']=ctr.fit(X_train, y_train).predict(X_test)\n",
    "n_df['gbr']=gbr.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgbr</th>\n",
       "      <th>lgbmr</th>\n",
       "      <th>ctr</th>\n",
       "      <th>gbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760.596497</td>\n",
       "      <td>743.259894</td>\n",
       "      <td>737.577104</td>\n",
       "      <td>761.234678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1520.306274</td>\n",
       "      <td>1540.187269</td>\n",
       "      <td>1509.106110</td>\n",
       "      <td>1484.705803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4989.241211</td>\n",
       "      <td>5524.827816</td>\n",
       "      <td>5289.175741</td>\n",
       "      <td>5069.717698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1844.035156</td>\n",
       "      <td>1857.262972</td>\n",
       "      <td>1816.263099</td>\n",
       "      <td>1872.407302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736.165283</td>\n",
       "      <td>749.374214</td>\n",
       "      <td>708.935448</td>\n",
       "      <td>738.023207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xgbr        lgbmr          ctr          gbr\n",
       "0   760.596497   743.259894   737.577104   761.234678\n",
       "1  1520.306274  1540.187269  1509.106110  1484.705803\n",
       "2  4989.241211  5524.827816  5289.175741  5069.717698\n",
       "3  1844.035156  1857.262972  1816.263099  1872.407302\n",
       "4   736.165283   749.374214   708.935448   738.023207"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884917297054854"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg=LinReg()\n",
    "linreg.fit(n_df.values, y_test)\n",
    "\n",
    "linreg.score(n_df.values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825273385126357"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8834076822273739"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8847170473928188"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825593620943495"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlxtend\n",
    "#!pip3 install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8750880205694244"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamodelo=StackingRegressor(regressors=[xgbr, lgbmr, ctr, gbr],\n",
    "                             meta_regressor=linreg)\n",
    "\n",
    "metamodelo.fit(X_train, y_train)\n",
    "metamodelo.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
