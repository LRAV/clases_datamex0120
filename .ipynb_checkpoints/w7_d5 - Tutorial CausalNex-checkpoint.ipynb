{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desde https://causalnex.readthedocs.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial CausalNex \n",
    "\n",
    "\n",
    "Este tutorial es un ejemplo de uso de CausalNex para estimar si un estudiante aprobabará o suspenderá un examen, basándose en características como relaciones familiares, soporte escolar y otros. Se usará el dataset de [Student Performance](https://archive.ics.uci.edu/ml/datasets/Student+Performance) publicado en [UCI Machine Learning Repository.](http://archive.ics.uci.edu/ml/index.php).\n",
    "\n",
    "La características del dataset son:\n",
    "\n",
    "+ 1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
    "+ 2 sex - student's sex (binary: 'F' - female or 'M' - male)\n",
    "+ 3 age - student's age (numeric: from 15 to 22)\n",
    "+ 4 address - student's home address type (binary: 'U' - urban or 'R' - rural)\n",
    "+ 5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
    "+ 6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
    "+ 7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "+ 8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n",
    "+ 9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "+ 10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
    "+ 11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
    "+ 12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n",
    "+ 13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "+ 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "+ 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "+ 16 schoolsup - extra educational support (binary: yes or no)\n",
    "+ 17 famsup - family educational support (binary: yes or no)\n",
    "+ 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "+ 19 activities - extra-curricular activities (binary: yes or no)\n",
    "+ 20 nursery - attended nursery school (binary: yes or no)\n",
    "+ 21 higher - wants to take higher education (binary: yes or no)\n",
    "+ 22 internet - Internet access at home (binary: yes or no)\n",
    "+ 23 romantic - with a romantic relationship (binary: yes or no)\n",
    "+ 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "+ 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "+ 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "+ 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "+ 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "+ 29 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "+ 30 absences - number of school absences (numeric: from 0 to 93)\n",
    "+ 31 G1 - first period grade (numeric: from 0 to 20)\n",
    "+ 31 G2 - second period grade (numeric: from 0 to 20)\n",
    "+ 32 G3 - final grade (numeric: from 0 to 20, output target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura \n",
    "\n",
    "Se puede definir la estructura de una red bayesiana (Bayesian Network - BN) basándose en el machine learning, el conocimiento experto o una combinación de ambos, donde expertos y algoritmos contribuyen igualmente a la solución del problema.\n",
    "\n",
    "Sin importar de qué manera sea, es fundamental validar la estructura evaluando la BN (esto se verá luego). En ésta sección nos centraremos en definir la estructura.\n",
    "\n",
    "\n",
    "\n",
    "## Estructura desde el conocimiento experto\n",
    "\n",
    "Podemos definir manualmente la estructura del modelo especificando las relaciones entre diferentes características.\n",
    "\n",
    "Primero, debemos crear una estructura vacía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure import StructureModel\n",
    "\n",
    "sm=StructureModel()\n",
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos especificar las relaciones entre características. Por ejemplo, supongamos que el experto nos dice que existe la siguiente relación causal: \n",
    "\n",
    "+ health -> absences   (salud -> ausencias)\n",
    "+ health -> G1         (salud -> notas del primer semestre)\n",
    "\n",
    "\n",
    "Podemos añadir esas relaciones a la estructura de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.add_edges_from([\n",
    "    ('health', 'absences'),\n",
    "    ('health', 'G1')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando la estructura\n",
    "\n",
    "Podemos examinar el StructureModel observando la salida de sm.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero a menudo es más intuitivo visualizarlo. CausalNex tiene un módulo de plot que nos permite hacer eso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "\n",
    "\n",
    "from causalnex.plots import plot_structure\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plot_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura desde ML\n",
    "\n",
    "Según crece el número de variables, o cuando no existe conocimiento experto, puede volverse tedioso definir toda la estructura de manera manual. Podemos usar CausalNex para extraer la estructura desde los datos. El algoritmo que se va a usar aquí es [NOTEARS](https://arxiv.org/abs/1803.01422).\n",
    "\n",
    "Para extraer la estructura, podemos usar todo el dataframe. No siempre es necesario usar train_test_split, dado que la estructura es un esfuerzo conjunto entre máquina y expertos.\n",
    "\n",
    "Pero antes de empezar, debemos procesar nuestros datos para poder alimentar el algoritmo.\n",
    "\n",
    "## Preparando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data=pd.read_csv('data/student-por.csv', delimiter=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando los datos, podemos ver que existen características numéricas y no-numéricas (categóricas). Podemos eliminar ciertas características 'sensibles' como el género, que no queremos usar en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['school', 'sex', 'age', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
    "\n",
    "data=data.drop(columns=drop_col)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, queremos que toda nuestra data sea numérica, puesto que es lo que espera el algoritmo NOTEARS. Podemos hacer esto con LabelEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "struct_data=data.copy()\n",
    "\n",
    "non_numeric_columns=list(struct_data.select_dtypes(exclude=[np.number]).columns)\n",
    "non_numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    struct_data[col]=le.fit_transform(struct_data[col])\n",
    "\n",
    "struct_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegados hasta aquí, ya podemos aplicar NOTEARS para que aprenda la estructura..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure.notears import from_pandas\n",
    "\n",
    "\n",
    "sm=from_pandas(struct_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(from_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... y visualizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón por la que tenemos un grafo completamente conectado es que no hemos aplicado un umbral (threshold) a las aristas 'débiles'. Esto se puede hacer de dos maneras distintas, o se especifica el valor del parámetro w_threshold en el método from_pandas, o podemos eliminar las aristas con el método remove_edges_below_threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "\n",
    "\n",
    "sm.remove_edges_below_threshold(0.8)\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta estructura, podemos ver que hay algunas relaciones que parecen ser intuitivamente correctas:\n",
    "\n",
    "+ Pstatus afecta a famrel - Si los padres están separados, la calidad de las relaciones familiares puede empobrecer el resultado.\n",
    "+ internet afecta a absences - La presencia de conxión a Internet en el hogar puede causar que el estudiante se salte las clases.\n",
    "+ studytime afecta a G1 - Tiempos más largos de estudio deberían de tener un impacto positivo en el resultado del estudiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, hay algunas relaciones que son ciertamente incorrectas:\n",
    "\n",
    "+ higher afecta a Mother’s education (Medu) - Esta relación no tiene sentido, ya que el hecho de que un estudiante desee tener educación superior no afecta a la educación de la madre. Esta relación podría ser al contrario. \n",
    "\n",
    "\n",
    "Para evitar esas relaciones erróneas, podemos volver a extraer la estructura añadiendo algunas restricciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "\n",
    "sm=from_pandas(struct_data, tabu_edges=[('higher', 'Medu')], w_threshold=0.8)\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificando la estructura\n",
    "\n",
    "Para corregir relaciones erróneas, podemos incorporar conocimiento experto en el modelo después de crear la estructura. Podemos modificar la estructura añadiendo o borrando aristas. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.add_edge('failures', 'G1')\n",
    "\n",
    "sm.remove_edge('Pstatus', 'G1')\n",
    "\n",
    "sm.remove_edge('address', 'G1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos visualizar la nueva estructura para confirmar que sea razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay dos subgrafos en la visualización:  Dalc->Walc y otro subgrafo grande. Podemos extraer el subgrafo más grande con StructureModel llamando al método get_largest_subgraph()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(12.0, 8.0)\n",
    "\n",
    "\n",
    "\n",
    "sm=sm.get_largest_subgraph()\n",
    "\n",
    "fig, ax, nodes=plot_structure(sm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de decidir la estructura final del modelo, podemos instanciar una red bayesiana (BayesianNetwork)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.network import BayesianNetwork\n",
    "\n",
    "bn=BayesianNetwork(sm)\n",
    "bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya estamos listos para seguir adelante con el aprendizaje de las distribuciones de probabilidad condicionada de diferentes características en la red bayesiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando la Distribución Condicional de una Red Bayesiana\n",
    "\n",
    "### Preparando la Discretización de los Datos\n",
    "\n",
    "\n",
    "Las redes bayesianas en CausalNex solo soportan distribuciones discretas. Cualquier característica continua, o características con un gran número de categorias, deben ser discretizadas antes de entrenar la red bayesiana. Los modelos que contengan variables como muchos posibles valores, típicamente tendrán un mal ajuste y un bajo rendimiento.\n",
    "\n",
    "Por ejemplo, consideremos P(G2|G1), donde G1 y G2 tienen valores posibles entre 0 y 20. La distribución discreta de probabilidad condicionada queda definida usando 21x21 (441) posibles combinaciones, la mayoría de las cuales será improbable observar.\n",
    "\n",
    "CausalNex provee algunos metodo de ayuda que hacen más fácil la discretización. Comencemos por reducir el número de categorías en algunas de las variables categóricas combinando valores similares. Convertiremos características numéricas en categoricas por discretización y luego se les asignarán las correspodientes etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardinalidad de las Características Categóricas\n",
    "\n",
    "Para reducir la cardinalidad de las características categoricas podemos definir un map {viejo_valor: nuevo_valor}, y usarlo para actualizar la característica. Por ejemplo, en la variable tiempo de estudio (studytime), si es mayor que 2 (2 significa de 2 a 5 horas de estudio, ver la descripción arriba o visitar https://archive.ics.uci.edu/ml/datasets/Student+Performance) pondremos long-studytime, y para el resto se pondrá short-studytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_data=data.copy()\n",
    "\n",
    "data_vals={col: data[col].unique() for col in data.columns}\n",
    "\n",
    "\n",
    "failures_map={v: 'no-failure' if v==[0]\n",
    "              else 'have-failure' for v in data_vals['failures']}\n",
    "\n",
    "\n",
    "studytime_map={v: 'short-studytime' if v in [1,2]\n",
    "               else 'long-studytime' for v in data_vals['studytime']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos definido los map {viejo_valor: nuevo_valor} podemos actualizar cada variable, aplicando la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_data['failures']=discretised_data['failures'].map(failures_map)\n",
    "\n",
    "discretised_data['studytime']=discretised_data['studytime'].map(studytime_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizando Característica Numéricas\n",
    "\n",
    "Para pasar de numérico a categórico, primero debemos discretizar. CausalNex tiene una clase para esto llamada\n",
    "causalnex.discretiser.Discretiser, la cual soporta varios métodos de discretización. Para nuestros datos, se aplicará el método 'fixed', dando valores fijos que definen los límites de la categoría (básicamente es hacer binning). Por ejemplo, la variable ausencias (absences) será discretizada en las categorías <1, de 1 a 9, y >=10. Cada una de ellas se etiquetará con un número entero desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.discretiser import Discretiser\n",
    "\n",
    "\n",
    "\n",
    "discretised_data['absences']=Discretiser(method='fixed',\n",
    "                             numeric_split_points=[1, 10]).transform(discretised_data['absences'].values)\n",
    "\n",
    "discretised_data['G1']=Discretiser(method='fixed',\n",
    "                                   numeric_split_points=[10]).transform(discretised_data['G1'].values)\n",
    "\n",
    "discretised_data['G2']=Discretiser(method='fixed',\n",
    "                                   numeric_split_points=[10]).transform(discretised_data['G2'].values)\n",
    "\n",
    "discretised_data['G3']=Discretiser(method='fixed',\n",
    "                                   numeric_split_points=[10]).transform(discretised_data['G3'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Etiquetas para Características Numéricas \n",
    "\n",
    "Para que las categorías discretizadas sean más legibles, podemos mapear las etiquetas de la misma manera que hicimos con las variables categóricas para que tengan un significado más evidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absences_map = {0: 'No-absence', 1: 'Low-absence', 2: 'High-absence'}\n",
    "\n",
    "G1_map = {0: 'Fail', 1: 'Pass'}\n",
    "G2_map = {0: 'Fail', 1: 'Pass'}\n",
    "G3_map = {0: 'Fail', 1: 'Pass'}\n",
    "\n",
    "\n",
    "\n",
    "discretised_data['absences'] = discretised_data['absences'].map(absences_map)\n",
    "\n",
    "discretised_data['G1'] = discretised_data['G1'].map(G1_map)\n",
    "discretised_data['G2'] = discretised_data['G2'].map(G2_map)\n",
    "discretised_data['G3'] = discretised_data['G3'].map(G3_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test_Split\n",
    "Al igual que en muchos otros modelo de machine learning, usaremos train_test_split para validar nuestros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 90% train y 10% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test=train_test_split(discretised_data, train_size=0.9, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Probabilidad\n",
    "\n",
    "Con la estructura del modelo ya obtenida y los datos discretizados, ya podemos ajustar la distribución de probabilidad de la red bayesiana. Para ello, el primer paso es especificar todos los estados en los que puede estar cada nodo. Esto se puede hacer desde los datos o se puede generar un diccionario con los valores de los nodos. Nosotros vamos a usar todo el dataset para evitar casos donde el estado del nodo exista en el test pero no exista en el train. Para aplicaciones en el mundo real, podría ser necesario usar diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn=bn.fit_node_states(discretised_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de las Distribuciones de Probabilidad Condicional\n",
    "\n",
    "El método fit_cpds de la red bayesiana (BayesianNetwork) acepta un dataset para aprender las distribuciones de probabilidad condicionada (CPDs por las siglas en inglés) de cada nodo, junto con un método que indica como hacer esta ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn=bn.fit_cpds(train, method='BayesianEstimator', bayes_prior='K2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(BayesianNetwork.fit_cpds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenidas las CPDs, podemos inspeccionarlas a través de sus propiedades, que vienen en un diccionario tipo nodo->cpd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.cpds['G1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los diccionarios de las CPDs están multi-indexados, por eso la función loc puede ser una manera muy útil de interactuar con ellos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir el Estado dados los Datos de Entrada \n",
    "\n",
    "El método de predicción de la red bayesiana nos permite hacer predicciones basándonos en los datos. Por ejemplo, queremos predecir si un estudiante suspenderá o aprobará sus examenes basándonos en los datos de entrada. Imagina que tenemos unos datos de entrada del estudiante tales que: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_data.loc[18, discretised_data.columns != 'G1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos datos, queremos predecir si el estudiante suspenderá su examen. Intuitivamente, deberíamos esperar que este estudiante suspenda porque estudia poco tiempo y ya ha suspendido anteriormente. Veamos como funciona la red bayesiana en este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=bn.predict(discretised_data, 'G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La predición es \\'{prediction}\\''.format(prediction=predictions.loc[18, 'G1_prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción realizada por la red bayesiana es que el estudiante suspende. Comparemos con la verdad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La verdad es \\'{truth}\\''.format(truth=discretised_data.loc[18, 'G1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el mismo resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad del modelo\n",
    "\n",
    "Para evaluar la calidad del modelo, CausalNex tiene dos formas: un reporte de clasificación (Classification Report) y la característica operativa del receptor (curva ROC) además del área bajo la curva ROC (AUC). Se discutirán ambas a continuación.\n",
    "\n",
    "\n",
    "### Reporte de Clasificación\n",
    "\n",
    "Para obtener un reporte de clasificación usando una red bayesiana, se necesita dar un set de test, y el nodo que estamos tratando de clasificar. El reporte predecirá el nodo objetivo para todas las filas del test, y evaluará como de bien se hacen esas predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.evaluation import classification_report\n",
    "\n",
    "classification_report(bn, test, 'G1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este reporte muestra que el modelo que hemos definido es capaz de clasificar si un estudiante aprobará sus examenes razonablemente bien.\n",
    "\n",
    "Para las predicciones donde el estudiante suspende, la precisión es buena, pero el recall es malo. Esto implica que podemos confiar en las predicciones para esa clase cuando se hacen, pero probablemente estaremos obviando algunas predicciones que deberiamos haber hecho. Tal vez esas predicciones no realizadas son el resultado de algo no considerado en nuestra estructura, esto podría ser un área interesante a explorar.\n",
    "\n",
    "\n",
    "### ROC / AUC\n",
    "\n",
    "La característica operativa del receptor (curva ROC), y el área debajo de la curva ROC (AUC) se pueden obtener usando el método roc_auc del modulo de evaluación de CausalNex. De nuevo, debemos tener hecho el train_test_split. La curva ROC se calcula por predicciones (micro-averaging) hechas sobre todas los estados (clases) del nodo objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.evaluation import roc_auc\n",
    "\n",
    "roc, auc=roc_auc(bn, test, 'G1')\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor AUC para nuestro modelo es alto, lo cual nos dice que funciona bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultando las Marginales\n",
    "\n",
    "Despúes de iterar sobre nuestra estructura, las CPDs y validar la calidad del modelo, podemos consultar a nuestro modelo bajo diferentes observaciones para generar nuevas ideas.\n",
    "\n",
    "\n",
    "\n",
    "### Marginales de Referencia\n",
    "\n",
    "Podemos realizar una consulta para ver las marginales de referencia que reflejen la población como un todo. Primero tenemos que actualizar nuestro modelo usando todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn=bn.fit_cpds(discretised_data, method='BayesianEstimator', bayes_prior='K2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ignorar estos warnings, nos están diciendo que se sustituyen las CPDs existentes.\n",
    "\n",
    "Para la inferencia, debemos crear un nuevo InferenceEngine para la red bayesiana que nos permita consultar el modelo. El método query calculará las verosimilitudes marginales de todos los estados para todos los nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.inference import InferenceEngine\n",
    "\n",
    "ie=InferenceEngine(bn)\n",
    "\n",
    "marginals=ie.query()\n",
    "marginals['G1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida observada nos dice que P(G1=Fail)=0.25, y P(G1=Pass)=0.75. Como comprobación rápida, podemos calcular la proporción de Fail en el dataset, debería ser aproximadamente lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "labels, counts=np.unique(discretised_data['G1'], return_counts=True)\n",
    "\n",
    "list(zip(labels, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proporción de estudiantes que suspenden es 157/(157+492)=0.242 , lo cual está muy cerca de la verosimilitud calculada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginales después de las Observaciones\n",
    "\n",
    "También podemos consultar las marginales de los estados en nuestra red dadas algunas observaciones. Estas observaciones se pueden hacer en cualquier sitio de la red, y su impacto se propagará a través del nodo de interés.\n",
    "\n",
    "Veamos la diferencia en G1 basándonos en el tiempo de estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_short=ie.query({'studytime': 'short-studytime'})\n",
    "marginals_long=ie.query({'studytime': 'long-studytime'})\n",
    "\n",
    "print('Marginal G1 | Short Studtyime', marginals_short['G1'])\n",
    "print('Marginal G1 | Long Studytime', marginals_long['G1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los datos, podemos ver que los estudiantes que estudian más tiempo tienen más probabilidad de aprobar los exámenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haciendo Cálculos\n",
    "\n",
    "CausalNex también soporta la realización de cálculos (Do-Calculus), permitiendo hacer intervenciones específicas. En esta sección veremos los métodos para hacer esto y que significan.\n",
    "\n",
    "### Actualizando la Distribución de un Nodo\n",
    "\n",
    "Podemos aplicar una intervención a cualquier nodo en nuestros datos, actualizando su distribución usando un operador. Se puede pensar que es algo como preguntar al modelo: ¿Qué pasaría si algo fuera diferente?. Por ejemplo, podríamos preguntar que ocurriría si el 100% de los estudiantes desean educación superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('distribution before do', ie.query()['higher'])\n",
    "\n",
    "ie.do_intervention('higher',\n",
    "                   {'yes': 1.0,\n",
    "                    'no': 0.0})\n",
    "\n",
    "\n",
    "print('distribution after do', ie.query()['higher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reestableciendo la Distribución de un Nodo\n",
    "\n",
    "Podemos resetear cualquier intervención que hayamos hecho usando el método reset_intervention, dándole el nodo que queremos resetear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie.reset_do('higher')\n",
    "\n",
    "\n",
    "ie.query()['higher']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efecto de la Intervención en las Marginales \n",
    "\n",
    "De nuevo, podemos usar query para examinar los efectos que provoca la intervención sobre las marginales. En este caso, queremos ver como cambia la verosimilitud de conseguir el aprobado si el 100% de los estudiantes quisieran tener educación superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('marginal G1', ie.query()['G1'])\n",
    "\n",
    "ie.do_intervention('higher',\n",
    "                   {'yes': 1.0,\n",
    "                    'no': 0.0})\n",
    "\n",
    "\n",
    "print('updated marginal G1', ie.query()['G1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, podemos observar que si el 100% de los estudiantes quisiera educsción superior (frente al 90% en toda la población), entonces la tasa de aprobado pasa del 74.7% al 79.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
